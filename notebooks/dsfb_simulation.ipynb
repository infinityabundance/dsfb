{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# DSFB Simulation Visualization\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/infinityabundance/dsfb/blob/main/notebooks/dsfb_simulation.ipynb)\n",
    "\n",
    "This notebook visualizes the results of the DSFB (Drift-Slew Fusion Bootstrap) simulation.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "To run this notebook:\n",
    "1. Clone the repository locally\n",
    "2. Run: `cargo run --release -p dsfb --example drift_impulse` to generate `out/sim.csv`\n",
    "3. Upload `out/sim.csv` when prompted (if running in Colab), or ensure it's in the correct path\n",
    "4. Run all cells\n",
    "\n",
    "Alternatively, the repository may include a pre-generated `sim.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    !pip install pandas matplotlib numpy\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload"
   },
   "outputs": [],
   "source": [
    "# Upload CSV file in Colab (uncomment if needed)\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# csv_path = list(uploaded.keys())[0]\n",
    "\n",
    "# Or auto-detect local path\n",
    "from pathlib import Path\n",
    "if Path('sim.csv').exists():\n",
    "    csv_path = 'sim.csv'\n",
    "elif Path('out/sim.csv').exists():\n",
    "    csv_path = 'out/sim.csv'\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not find sim.csv or out/sim.csv. Generate it with: cargo run --release -p dsfb --example drift_impulse\")\n",
    "\n",
    "print(f\"Using CSV: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [],
   "source": [
    "# Load simulation data\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Loaded {len(df)} time steps\")\n",
    "print(f\"Time range: {df['t'].min():.2f} to {df['t'].max():.2f}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_estimates"
   },
   "outputs": [],
   "source": [
    "# Plot: True state vs estimates\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(df['t'], df['phi_true'], 'k-', linewidth=2, label='True φ', alpha=0.8)\n",
    "ax.plot(df['t'], df['phi_mean'], 'b--', linewidth=1.5, label='Mean Fusion', alpha=0.7)\n",
    "ax.plot(df['t'], df['phi_freqonly'], 'g--', linewidth=1.5, label='Freq-Only', alpha=0.7)\n",
    "ax.plot(df['t'], df['phi_dsfb'], 'r-', linewidth=1.5, label='DSFB', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('φ (position)', fontsize=12)\n",
    "ax.set_title('Position Estimates Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_errors"
   },
   "outputs": [],
   "source": [
    "# Plot: Error curves\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(df['t'], df['err_mean'], 'b-', linewidth=1.5, label='Mean Fusion Error', alpha=0.7)\n",
    "ax.plot(df['t'], df['err_freqonly'], 'g-', linewidth=1.5, label='Freq-Only Error', alpha=0.7)\n",
    "ax.plot(df['t'], df['err_dsfb'], 'r-', linewidth=1.5, label='DSFB Error', alpha=0.8)\n",
    "\n",
    "# Mark impulse region\n",
    "impulse_start = 3.0  # Adjust based on actual simulation config\n",
    "impulse_end = 4.0\n",
    "ax.axvspan(impulse_start, impulse_end, alpha=0.2, color='orange', label='Impulse Period')\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Absolute Error', fontsize=12)\n",
    "ax.set_title('Estimation Errors', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_trust"
   },
   "outputs": [],
   "source": [
    "# Plot: Trust weight and EMA residual for channel 2\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Trust weight\n",
    "ax1.plot(df['t'], df['w2'], 'purple', linewidth=2, label='Channel 2 Trust Weight')\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Equal Weight')\n",
    "ax1.axvspan(impulse_start, impulse_end, alpha=0.2, color='orange', label='Impulse Period')\n",
    "ax1.set_ylabel('Weight w₂', fontsize=12)\n",
    "ax1.set_title('Trust Weight Adaptation', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1])\n",
    "\n",
    "# EMA residual\n",
    "ax2.plot(df['t'], df['s2'], 'orange', linewidth=2, label='Channel 2 EMA Residual')\n",
    "ax2.axvspan(impulse_start, impulse_end, alpha=0.2, color='orange', label='Impulse Period')\n",
    "ax2.set_xlabel('Time (s)', fontsize=12)\n",
    "ax2.set_ylabel('EMA Residual s₂', fontsize=12)\n",
    "ax2.set_title('Residual Tracking', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "metrics"
   },
   "outputs": [],
   "source": [
    "# Compute and display metrics\n",
    "def rms_error(errors):\n",
    "    return np.sqrt(np.mean(errors**2))\n",
    "\n",
    "rms_mean = rms_error(df['err_mean'])\n",
    "rms_freqonly = rms_error(df['err_freqonly'])\n",
    "rms_dsfb = rms_error(df['err_dsfb'])\n",
    "\n",
    "# Find impulse indices\n",
    "impulse_mask = (df['t'] >= impulse_start) & (df['t'] < impulse_end)\n",
    "peak_mean = df.loc[impulse_mask, 'err_mean'].max()\n",
    "peak_freqonly = df.loc[impulse_mask, 'err_freqonly'].max()\n",
    "peak_dsfb = df.loc[impulse_mask, 'err_dsfb'].max()\n",
    "\n",
    "# Create metrics table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Method': ['Mean Fusion', 'Freq-Only', 'DSFB'],\n",
    "    'RMS Error': [rms_mean, rms_freqonly, rms_dsfb],\n",
    "    'Peak Error (Impulse)': [peak_mean, peak_freqonly, peak_dsfb]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate improvement\n",
    "improvement_vs_mean = (rms_mean - rms_dsfb) / rms_mean * 100\n",
    "improvement_vs_freqonly = (rms_freqonly - rms_dsfb) / rms_freqonly * 100\n",
    "\n",
    "print(f\"\\nDSFB Improvement:\")\n",
    "print(f\"  vs Mean Fusion: {improvement_vs_mean:.1f}% reduction in RMS error\")\n",
    "print(f\"  vs Freq-Only:   {improvement_vs_freqonly:.1f}% reduction in RMS error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Minimum trust weight w₂: {df['w2'].min():.4f}\")\n",
    "print(f\"Maximum trust weight w₂: {df['w2'].max():.4f}\")\n",
    "print(f\"Mean trust weight w₂: {df['w2'].mean():.4f}\")\n",
    "print(f\"\\nMaximum EMA residual s₂: {df['s2'].max():.4f}\")\n",
    "print(f\"Final EMA residual s₂: {df['s2'].iloc[-1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dsfb_simulation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
