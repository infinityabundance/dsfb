{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# dsfb-add Colab Sweep Notebook\n",
    "\n",
    "This notebook loads Rust-generated CSVs from `/output-dsfb-add/<timestamp>/` and generates Plotly PNG figures for AET, IWLT, TCP, and RLT.\n",
    "\n",
    "It is designed to fail closed if either the notebook copy or the Colab package environment is stale relative to the repository `main` branch.\n",
    "For Colab reliability it uses the self-contained `kaleido==0.2.1` export path instead of Chrome-managed Kaleido v1.\n",
    "\n",
    "Recommended workflow:\n",
    "\n",
    "1. Open the notebook from the repository Colab link on the `main` branch.\n",
    "2. Use `Runtime -> Restart session and run all` when Colab prompts after the install cell.\n",
    "3. By default the notebook clones the repository, runs `cargo run -p dsfb-add --bin dsfb_add_sweep`, and uses the fresh timestamped output.\n",
    "4. Only set `OUTPUT_DIR` explicitly if you intentionally want to analyze a specific existing run directory.\n",
    "5. The generated PNGs and `tcp_ph_summary.csv` are written back into the same timestamped directory as the CSVs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade \"plotly==6.1.1\" \"kaleido==0.2.1\" \"ripser==0.6.12\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "freshness"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from importlib.metadata import version\n",
    "from urllib.request import urlopen\n",
    "\n",
    "NOTEBOOK_VERSION = \"2026-03-01-10\"\n",
    "NOTEBOOK_RAW_URL = \"https://raw.githubusercontent.com/infinityabundance/dsfb/main/crates/dsfb-add/dsfb_add_sweep.ipynb\"\n",
    "EXPECTED_PACKAGE_VERSIONS = {\n",
    "    \"plotly\": \"6.1.1\",\n",
    "    \"kaleido\": \"0.2.1\",\n",
    "}\n",
    "\n",
    "for prefix in (\"plotly\", \"kaleido\", \"ripser\"):\n",
    "    loaded = [name for name in list(sys.modules) if name == prefix or name.startswith(prefix + \".\")]\n",
    "    for name in loaded:\n",
    "        del sys.modules[name]\n",
    "\n",
    "remote_nb = json.load(urlopen(NOTEBOOK_RAW_URL))\n",
    "remote_version = remote_nb.get(\"metadata\", {}).get(\"dsfb_add_notebook_version\")\n",
    "if remote_version != NOTEBOOK_VERSION:\n",
    "    raise RuntimeError(\n",
    "        f\"Stale notebook copy detected. This notebook is {NOTEBOOK_VERSION}, but main has {remote_version}. \"\n",
    "        \"Reopen the notebook from the repository Colab link.\"\n",
    "    )\n",
    "\n",
    "installed_versions = {name: version(name) for name in EXPECTED_PACKAGE_VERSIONS}\n",
    "mismatches = {\n",
    "    name: (installed_versions[name], expected)\n",
    "    for name, expected in EXPECTED_PACKAGE_VERSIONS.items()\n",
    "    if installed_versions[name] != expected\n",
    "}\n",
    "if mismatches:\n",
    "    mismatch_text = \"\\n\".join(\n",
    "        f\" - {name}: installed {installed}, expected {expected}\"\n",
    "        for name, (installed, expected) in mismatches.items()\n",
    "    )\n",
    "    raise RuntimeError(\n",
    "        \"Notebook environment is stale. Re-run the install cell, then restart the Colab runtime. \"\n",
    "        \"Version mismatches:\\n\" + mismatch_text\n",
    "    )\n",
    "\n",
    "print(\"Notebook freshness check passed:\", NOTEBOOK_VERSION)\n",
    "print(\"Pinned packages:\", installed_versions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Leave OUTPUT_DIR as None to use a fresh Colab-generated run by default.\n",
    "# Or set it explicitly, for example:\n",
    "# OUTPUT_DIR = Path(\"/content/output-dsfb-add/2026-03-01T12-00-00Z\")\n",
    "OUTPUT_DIR = None\n",
    "RUN_RUST_SWEEP_IN_COLAB = True\n",
    "REPO_URL = \"https://github.com/infinityabundance/dsfb.git\"\n",
    "REPO_DIR = Path(\"/content/dsfb\")\n",
    "CARGO_BIN_DIR = Path(\"/root/.cargo/bin\")\n",
    "TCP_PERSISTENCE_THRESHOLD = 0.05\n",
    "TCP_SMOOTHING_WINDOW = 5\n",
    "\n",
    "OUTPUT_ROOT_CANDIDATES = [\n",
    "    REPO_DIR / \"output-dsfb-add\",\n",
    "    Path(\"/content/output-dsfb-add\"),\n",
    "    Path(\"/content/dsfb/output-dsfb-add\"),\n",
    "    Path(\"/content/drive/MyDrive/output-dsfb-add\"),\n",
    "    Path(\"output-dsfb-add\"),\n",
    "]\n",
    "\n",
    "OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from IPython.display import Image, display\n",
    "from ripser import ripser\n",
    "\n",
    "if plotly.__version__ != EXPECTED_PACKAGE_VERSIONS[\"plotly\"]:\n",
    "    raise RuntimeError(\n",
    "        f\"Imported stale plotly module {plotly.__version__}; expected {EXPECTED_PACKAGE_VERSIONS['plotly']}. \"\n",
    "        \"Restart the Colab runtime and run all cells again.\"\n",
    "    )\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "pio.templates.default = \"none\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helpers"
   },
   "outputs": [],
   "source": [
    "def require_file(path: Path) -> Path:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    return path\n",
    "\n",
    "def latest_timestamped_dir(root: Path):\n",
    "    if not root.exists() or not root.is_dir():\n",
    "        return None\n",
    "    candidates = sorted(path for path in root.iterdir() if path.is_dir())\n",
    "    return candidates[-1] if candidates else None\n",
    "\n",
    "def resolve_output_dir(explicit_dir, candidate_roots):\n",
    "    if explicit_dir is not None:\n",
    "        explicit_dir = Path(explicit_dir)\n",
    "        if explicit_dir.exists() and explicit_dir.is_dir():\n",
    "            return explicit_dir\n",
    "        raise FileNotFoundError(\n",
    "            f\"Configured OUTPUT_DIR does not exist: {explicit_dir}. Upload or mount your run folder first.\"\n",
    "        )\n",
    "\n",
    "    for root in candidate_roots:\n",
    "        candidate = latest_timestamped_dir(root)\n",
    "        if candidate is not None:\n",
    "            return candidate\n",
    "\n",
    "    searched = \"\\n\".join(f\" - {root}\" for root in candidate_roots)\n",
    "    raise FileNotFoundError(\n",
    "        \"No output-dsfb-add run directory was found. Upload or mount the Rust-generated \"\n",
    "        \"output folder, or set OUTPUT_DIR explicitly. Searched:\\n\" + searched\n",
    "    )\n",
    "\n",
    "def save_png(fig, filename: str, width: int = 1400, height: int = 900, scale: int = 2) -> Path:\n",
    "    target = OUTPUT_DIR / filename\n",
    "    fig.write_image(target, width=width, height=height, scale=scale)\n",
    "    return target\n",
    "\n",
    "def display_saved_png(path: Path):\n",
    "    display(Image(filename=str(path)))\n",
    "    return path\n",
    "\n",
    "def hex_to_rgba(hex_color: str, alpha: float) -> str:\n",
    "    hex_color = hex_color.lstrip(\"#\")\n",
    "    if len(hex_color) != 6:\n",
    "        raise ValueError(f\"Expected 6-digit hex color, got {hex_color}\")\n",
    "    r = int(hex_color[0:2], 16)\n",
    "    g = int(hex_color[2:4], 16)\n",
    "    b = int(hex_color[4:6], 16)\n",
    "    return f\"rgba({r}, {g}, {b}, {alpha})\"\n",
    "\n",
    "def make_line_figure(\n",
    "    df,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    title: str,\n",
    "    y_title: str,\n",
    "    color: str = \"#1f77b4\",\n",
    "    showlegend: bool = False,\n",
    "    name: str | None = None,\n",
    "):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[x_col],\n",
    "            y=df[y_col],\n",
    "            mode=\"lines+markers\",\n",
    "            line={\"width\": 3, \"color\": color},\n",
    "            marker={\"size\": 6, \"color\": color},\n",
    "            name=name or y_col,\n",
    "            showlegend=showlegend,\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        font={\"size\": 16, \"color\": \"#222222\"},\n",
    "        margin={\"l\": 80, \"r\": 40, \"t\": 90, \"b\": 70},\n",
    "        showlegend=showlegend,\n",
    "        legend={\"orientation\": \"h\", \"yanchor\": \"bottom\", \"y\": 1.02, \"xanchor\": \"right\", \"x\": 1.0},\n",
    "    )\n",
    "    fig.update_xaxes(title=\"lambda\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "    fig.update_yaxes(title=y_title, showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "    return fig\n",
    "\n",
    "def make_band_figure(\n",
    "    df,\n",
    "    x_col: str,\n",
    "    mean_col: str,\n",
    "    std_col: str,\n",
    "    title: str,\n",
    "    y_title: str,\n",
    "    color: str = \"#e7298a\",\n",
    "    line_name: str | None = None,\n",
    "):\n",
    "    fig = go.Figure()\n",
    "    upper = df[mean_col] + df[std_col]\n",
    "    lower = df[mean_col] - df[std_col]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[x_col],\n",
    "            y=upper,\n",
    "            mode=\"lines\",\n",
    "            line={\"width\": 0},\n",
    "            hoverinfo=\"skip\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[x_col],\n",
    "            y=lower,\n",
    "            mode=\"lines\",\n",
    "            line={\"width\": 0},\n",
    "            fill=\"tonexty\",\n",
    "            fillcolor=hex_to_rgba(color, 0.18),\n",
    "            hoverinfo=\"skip\",\n",
    "            name=\"Â±1 std\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[x_col],\n",
    "            y=df[mean_col],\n",
    "            mode=\"lines+markers\",\n",
    "            line={\"width\": 3, \"color\": color},\n",
    "            marker={\"size\": 6, \"color\": color},\n",
    "            name=line_name or mean_col,\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        font={\"size\": 16, \"color\": \"#222222\"},\n",
    "        margin={\"l\": 80, \"r\": 40, \"t\": 90, \"b\": 70},\n",
    "        showlegend=True,\n",
    "        legend={\"orientation\": \"h\", \"yanchor\": \"bottom\", \"y\": 1.02, \"xanchor\": \"right\", \"x\": 1.0},\n",
    "    )\n",
    "    fig.update_xaxes(title=\"lambda\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "    fig.update_yaxes(title=y_title, showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "    return fig\n",
    "\n",
    "def make_multiline_figure(df, x_col: str, series_specs, title: str, y_title: str):\n",
    "    fig = go.Figure()\n",
    "    for spec in series_specs:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[x_col],\n",
    "                y=df[spec[\"y_col\"]],\n",
    "                mode=\"lines\",\n",
    "                line={\"width\": 3, \"color\": spec[\"color\"]},\n",
    "                name=spec[\"name\"],\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        font={\"size\": 16, \"color\": \"#222222\"},\n",
    "        margin={\"l\": 80, \"r\": 40, \"t\": 90, \"b\": 70},\n",
    "        showlegend=True,\n",
    "        legend={\"orientation\": \"h\", \"yanchor\": \"bottom\", \"y\": 1.02, \"xanchor\": \"right\", \"x\": 1.0},\n",
    "    )\n",
    "    fig.update_xaxes(title=\"lambda\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "    fig.update_yaxes(title=y_title, showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False, range=[-0.02, 1.02])\n",
    "    return fig\n",
    "\n",
    "def minmax_norm(values):\n",
    "    values = pd.Series(values, copy=False)\n",
    "    span = values.max() - values.min()\n",
    "    if span <= 1e-12:\n",
    "        return pd.Series(np.zeros(len(values)), index=values.index)\n",
    "    return (values - values.min()) / span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bootstrap"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def unique_paths(paths):\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for path in paths:\n",
    "        key = str(path)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        out.append(path)\n",
    "        seen.add(key)\n",
    "    return out\n",
    "\n",
    "def cargo_env():\n",
    "    env = os.environ.copy()\n",
    "    env[\"PATH\"] = f\"{CARGO_BIN_DIR}:{env['PATH']}\"\n",
    "    return env\n",
    "\n",
    "def run_cmd(args, cwd=None, env=None):\n",
    "    args = [str(arg) for arg in args]\n",
    "    print(\"+\", \" \".join(args))\n",
    "    subprocess.run(args, cwd=str(cwd) if cwd else None, env=env, check=True)\n",
    "\n",
    "def ensure_cargo_installed():\n",
    "    if shutil.which(\"cargo\", path=cargo_env()[\"PATH\"]):\n",
    "        return\n",
    "    run_cmd([\n",
    "        \"bash\",\n",
    "        \"-lc\",\n",
    "        \"curl https://sh.rustup.rs -sSf | sh -s -- -y --profile minimal\",\n",
    "    ])\n",
    "    if not shutil.which(\"cargo\", path=cargo_env()[\"PATH\"]):\n",
    "        raise RuntimeError(\"cargo is unavailable after rustup installation\")\n",
    "\n",
    "def ensure_repo_checkout():\n",
    "    if (REPO_DIR / \".git\").exists():\n",
    "        return\n",
    "    REPO_DIR.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if REPO_DIR.exists() and any(REPO_DIR.iterdir()):\n",
    "        raise RuntimeError(\n",
    "            f\"Repo directory exists but is not a git checkout: {REPO_DIR}. Remove it or set OUTPUT_DIR explicitly.\"\n",
    "        )\n",
    "    run_cmd([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR])\n",
    "\n",
    "def generate_fresh_output_if_requested():\n",
    "    if OUTPUT_DIR is not None or not RUN_RUST_SWEEP_IN_COLAB:\n",
    "        return\n",
    "    ensure_cargo_installed()\n",
    "    ensure_repo_checkout()\n",
    "    run_cmd([\"cargo\", \"run\", \"-p\", \"dsfb-add\", \"--bin\", \"dsfb_add_sweep\"], cwd=REPO_DIR, env=cargo_env())\n",
    "\n",
    "generate_fresh_output_if_requested()\n",
    "OUTPUT_ROOT_CANDIDATES = unique_paths(OUTPUT_ROOT_CANDIDATES)\n",
    "OUTPUT_DIR = resolve_output_dir(OUTPUT_DIR, OUTPUT_ROOT_CANDIDATES)\n",
    "OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aet-figure"
   },
   "outputs": [],
   "source": [
    "aet = pd.read_csv(require_file(OUTPUT_DIR / \"aet_sweep.csv\"))\n",
    "\n",
    "fig_aet = make_line_figure(aet, \"lambda\", \"echo_slope\", \"AET Echo Slope vs Lambda\", \"echo_slope\")\n",
    "aet_png = save_png(fig_aet, \"fig_aet_echo_slope_vs_lambda.png\")\n",
    "display_saved_png(aet_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwlt-figure"
   },
   "outputs": [],
   "source": [
    "iwlt = pd.read_csv(require_file(OUTPUT_DIR / \"iwlt_sweep.csv\"))\n",
    "\n",
    "fig_iwlt = make_line_figure(iwlt, \"lambda\", \"entropy_density\", \"IWLT Entropy Density vs Lambda\", \"entropy_density\", color=\"#d95f02\")\n",
    "iwlt_png = save_png(fig_iwlt, \"fig_iwlt_entropy_density_vs_lambda.png\")\n",
    "display_saved_png(iwlt_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlt-figure"
   },
   "outputs": [],
   "source": [
    "rlt = pd.read_csv(require_file(OUTPUT_DIR / \"rlt_sweep.csv\"))\n",
    "\n",
    "fig_rlt_escape = make_line_figure(rlt, \"lambda\", \"escape_rate\", \"RLT Escape Rate vs Lambda\", \"escape_rate\", color=\"#7570b3\")\n",
    "rlt_escape_png = save_png(fig_rlt_escape, \"fig_rlt_escape_rate_vs_lambda.png\")\n",
    "\n",
    "fig_rlt_expansion = make_line_figure(rlt, \"lambda\", \"expansion_ratio\", \"RLT Expansion Ratio vs Lambda\", \"expansion_ratio\", color=\"#1b9e77\")\n",
    "rlt_expansion_png = save_png(fig_rlt_expansion, \"fig_rlt_expansion_ratio_vs_lambda.png\")\n",
    "\n",
    "transition_candidates = rlt.index[rlt[\"escape_rate\"] >= 0.8].tolist()\n",
    "if transition_candidates:\n",
    "    transition_idx = int(transition_candidates[0])\n",
    "    center_lambda = float(rlt.loc[transition_idx, \"lambda\"])\n",
    "    zoom_half_width = max(0.08, 10.0 * float(np.diff(rlt[\"lambda\"]).mean()))\n",
    "else:\n",
    "    center_lambda = float(rlt[\"lambda\"].iloc[len(rlt) // 2])\n",
    "    zoom_half_width = 0.15\n",
    "\n",
    "zoom_min = max(float(rlt[\"lambda\"].min()), center_lambda - zoom_half_width)\n",
    "zoom_max = min(float(rlt[\"lambda\"].max()), center_lambda + zoom_half_width)\n",
    "rlt_zoom = rlt[(rlt[\"lambda\"] >= zoom_min) & (rlt[\"lambda\"] <= zoom_max)].copy()\n",
    "if len(rlt_zoom) < 3:\n",
    "    rlt_zoom = rlt.copy()\n",
    "\n",
    "fig_rlt_zoom = go.Figure()\n",
    "fig_rlt_zoom.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rlt_zoom[\"lambda\"],\n",
    "        y=rlt_zoom[\"expansion_ratio\"],\n",
    "        mode=\"lines+markers\",\n",
    "        line={\"width\": 3, \"color\": \"#1b9e77\"},\n",
    "        marker={\"size\": 6, \"color\": \"#1b9e77\"},\n",
    "        name=\"Expansion ratio\",\n",
    "    )\n",
    ")\n",
    "fig_rlt_zoom.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rlt_zoom[\"lambda\"],\n",
    "        y=rlt_zoom[\"escape_rate\"],\n",
    "        mode=\"lines+markers\",\n",
    "        line={\"width\": 3, \"color\": \"#7570b3\"},\n",
    "        marker={\"size\": 6, \"color\": \"#7570b3\"},\n",
    "        name=\"Escape rate\",\n",
    "    )\n",
    ")\n",
    "fig_rlt_zoom.update_layout(\n",
    "    title=\"RLT Expansion Ratio vs Lambda (zoomed transition)\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    font={\"size\": 16, \"color\": \"#222222\"},\n",
    "    margin={\"l\": 80, \"r\": 40, \"t\": 90, \"b\": 70},\n",
    "    showlegend=True,\n",
    "    legend={\"orientation\": \"h\", \"yanchor\": \"bottom\", \"y\": 1.02, \"xanchor\": \"right\", \"x\": 1.0},\n",
    ")\n",
    "fig_rlt_zoom.update_xaxes(title=\"lambda\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "fig_rlt_zoom.update_yaxes(title=\"normalized transport\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "rlt_zoom_png = save_png(fig_rlt_zoom, \"fig_rlt_expansion_ratio_vs_lambda_zoom.png\")\n",
    "\n",
    "display_saved_png(rlt_escape_png)\n",
    "display_saved_png(rlt_expansion_png)\n",
    "display_saved_png(rlt_zoom_png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlt-example-note"
   },
   "source": [
    "## RLT Example Trajectories\n",
    "\n",
    "The Rust sweep exports representative bounded and expanding resonance walks in `rlt_examples/` so the transition in the RLT summary curves can be inspected directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlt-examples"
   },
   "outputs": [],
   "source": [
    "rlt_examples_dir = require_file(OUTPUT_DIR / \"rlt_examples\")\n",
    "bounded_path = sorted(rlt_examples_dir.glob(\"trajectory_bounded_lambda_*.csv\"))[0]\n",
    "expanding_path = sorted(rlt_examples_dir.glob(\"trajectory_expanding_lambda_*.csv\"))[0]\n",
    "\n",
    "rlt_bounded = pd.read_csv(bounded_path)\n",
    "rlt_expanding = pd.read_csv(expanding_path)\n",
    "\n",
    "bounded_lambda = float(rlt_bounded[\"lambda\"].iloc[0])\n",
    "expanding_lambda = float(rlt_expanding[\"lambda\"].iloc[0])\n",
    "\n",
    "fig_rlt_bounded = go.Figure()\n",
    "fig_rlt_bounded.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rlt_bounded[\"step\"],\n",
    "        y=rlt_bounded[\"vertex_id\"],\n",
    "        mode=\"lines+markers\",\n",
    "        line={\"width\": 2.5, \"color\": \"#386cb0\"},\n",
    "        marker={\"size\": 5, \"color\": rlt_bounded[\"distance_from_start\"], \"colorscale\": \"Blues\", \"showscale\": False},\n",
    "        name=\"Bounded trajectory\",\n",
    "        text=rlt_bounded[\"distance_from_start\"],\n",
    "        hovertemplate=\"step=%{x}<br>vertex_id=%{y}<br>distance=%{text}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig_rlt_bounded.update_layout(\n",
    "    title=f\"RLT Trajectory in Bounded Regime (lambda = {bounded_lambda:.3f})\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    font={\"size\": 16, \"color\": \"#222222\"},\n",
    "    margin={\"l\": 80, \"r\": 40, \"t\": 90, \"b\": 70},\n",
    "    showlegend=False,\n",
    ")\n",
    "fig_rlt_bounded.update_xaxes(title=\"step\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "fig_rlt_bounded.update_yaxes(title=\"vertex_id\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "rlt_bounded_png = save_png(fig_rlt_bounded, \"fig_rlt_trajectory_bounded.png\")\n",
    "\n",
    "fig_rlt_expanding = go.Figure()\n",
    "fig_rlt_expanding.add_trace(\n",
    "    go.Scatter(\n",
    "        x=rlt_expanding[\"step\"],\n",
    "        y=rlt_expanding[\"vertex_id\"],\n",
    "        mode=\"lines+markers\",\n",
    "        line={\"width\": 2.5, \"color\": \"#ef3b2c\"},\n",
    "        marker={\"size\": 5, \"color\": rlt_expanding[\"distance_from_start\"], \"colorscale\": \"Reds\", \"showscale\": False},\n",
    "        name=\"Expanding trajectory\",\n",
    "        text=rlt_expanding[\"distance_from_start\"],\n",
    "        hovertemplate=\"step=%{x}<br>vertex_id=%{y}<br>distance=%{text}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig_rlt_expanding.update_layout(\n",
    "    title=f\"RLT Trajectory in Expanding Regime (lambda = {expanding_lambda:.3f})\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    font={\"size\": 16, \"color\": \"#222222\"},\n",
    "    margin={\"l\": 80, \"r\": 40, \"t\": 90, \"b\": 70},\n",
    "    showlegend=False,\n",
    ")\n",
    "fig_rlt_expanding.update_xaxes(title=\"step\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "fig_rlt_expanding.update_yaxes(title=\"vertex_id\", showgrid=True, gridcolor=\"#d9d9d9\", zeroline=False)\n",
    "rlt_expanding_png = save_png(fig_rlt_expanding, \"fig_rlt_trajectory_expanding.png\")\n",
    "\n",
    "display_saved_png(rlt_bounded_png)\n",
    "display_saved_png(rlt_expanding_png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcp-note"
   },
   "source": [
    "## TCP persistent-homology summary\n",
    "\n",
    "The Rust sweep exports multiple deterministic point-cloud runs per lambda in `tcp_points/`. The cell below computes H1 count and total-persistence statistics across those runs and saves a `tcp_ph_summary.csv` for downstream comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcp-figure"
   },
   "outputs": [],
   "source": [
    "tcp = pd.read_csv(require_file(OUTPUT_DIR / \"tcp_sweep.csv\"))\n",
    "point_pattern = re.compile(r\"lambda_(\\d+)_run_(\\d+)\\.csv$\")\n",
    "point_groups = defaultdict(list)\n",
    "\n",
    "for point_file in sorted((OUTPUT_DIR / \"tcp_points\").glob(\"lambda_*_run_*.csv\")):\n",
    "    match = point_pattern.search(point_file.name)\n",
    "    if not match:\n",
    "        continue\n",
    "    lambda_idx = int(match.group(1))\n",
    "    point_groups[lambda_idx].append(point_file)\n",
    "\n",
    "ph_rows = []\n",
    "for lambda_idx in sorted(point_groups):\n",
    "    betti_counts = []\n",
    "    total_persistences = []\n",
    "    for point_file in sorted(point_groups[lambda_idx]):\n",
    "        points = pd.read_csv(point_file)[[\"x\", \"y\"]].to_numpy()\n",
    "        diagrams = ripser(points, maxdim=1)[\"dgms\"]\n",
    "        h1 = diagrams[1] if len(diagrams) > 1 else np.empty((0, 2))\n",
    "        if len(h1):\n",
    "            lifetimes = h1[:, 1] - h1[:, 0]\n",
    "            persistent = h1[np.isfinite(h1[:, 1]) & (lifetimes > TCP_PERSISTENCE_THRESHOLD)]\n",
    "            persistent_lifetimes = persistent[:, 1] - persistent[:, 0] if len(persistent) else np.empty((0,))\n",
    "        else:\n",
    "            persistent = np.empty((0, 2))\n",
    "            persistent_lifetimes = np.empty((0,))\n",
    "\n",
    "        betti_counts.append(float(len(persistent)))\n",
    "        total_persistences.append(float(persistent_lifetimes.sum()))\n",
    "\n",
    "    ph_rows.append(\n",
    "        {\n",
    "            \"lambda\": float(tcp.loc[lambda_idx, \"lambda\"]),\n",
    "            \"betti1_mean\": float(np.mean(betti_counts)),\n",
    "            \"betti1_std\": float(np.std(betti_counts)),\n",
    "            \"total_persistence_mean\": float(np.mean(total_persistences)),\n",
    "            \"total_persistence_std\": float(np.std(total_persistences)),\n",
    "            \"num_runs\": int(len(betti_counts)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "tcp_ph_summary_df = pd.DataFrame(ph_rows).sort_values(\"lambda\").reset_index(drop=True)\n",
    "tcp_ph_summary_df[\"betti1_mean_smooth\"] = (\n",
    "    tcp_ph_summary_df[\"betti1_mean\"].rolling(TCP_SMOOTHING_WINDOW, center=True, min_periods=1).mean()\n",
    ")\n",
    "tcp_ph_summary_df[\"betti1_std_smooth\"] = (\n",
    "    tcp_ph_summary_df[\"betti1_std\"].rolling(TCP_SMOOTHING_WINDOW, center=True, min_periods=1).mean()\n",
    ")\n",
    "tcp_ph_summary_path = OUTPUT_DIR / \"tcp_ph_summary.csv\"\n",
    "tcp_ph_summary_df.to_csv(tcp_ph_summary_path, index=False)\n",
    "\n",
    "fig_tcp_betti = make_band_figure(\n",
    "    tcp_ph_summary_df,\n",
    "    \"lambda\",\n",
    "    \"betti1_mean_smooth\",\n",
    "    \"betti1_std_smooth\",\n",
    "    \"TCP Betti-1 Mean vs Lambda\",\n",
    "    \"betti1_mean (smoothed)\",\n",
    "    color=\"#e7298a\",\n",
    "    line_name=\"Smoothed Betti-1 mean\",\n",
    ")\n",
    "tcp_betti_png = save_png(fig_tcp_betti, \"fig_tcp_betti1_mean_vs_lambda.png\")\n",
    "\n",
    "fig_tcp_persistence = make_band_figure(\n",
    "    tcp_ph_summary_df,\n",
    "    \"lambda\",\n",
    "    \"total_persistence_mean\",\n",
    "    \"total_persistence_std\",\n",
    "    \"TCP Total Persistence vs Lambda\",\n",
    "    \"total_persistence_mean\",\n",
    "    color=\"#66a61e\",\n",
    "    line_name=\"Total persistence mean\",\n",
    ")\n",
    "tcp_persistence_png = save_png(fig_tcp_persistence, \"fig_tcp_total_persistence_vs_lambda.png\")\n",
    "\n",
    "display_saved_png(tcp_betti_png)\n",
    "display_saved_png(tcp_persistence_png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cross-layer-note"
   },
   "source": [
    "## Cross-Layer Structural Summary\n",
    "\n",
    "This overlay compares min-max normalized AET echo slope, IWLT entropy density, and RLT expansion ratio on the common lambda grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cross-layer-figure"
   },
   "outputs": [],
   "source": [
    "cross_layer_df = (\n",
    "    aet[[\"lambda\", \"echo_slope\"]]\n",
    "    .merge(iwlt[[\"lambda\", \"entropy_density\"]], on=\"lambda\", how=\"inner\")\n",
    "    .merge(rlt[[\"lambda\", \"expansion_ratio\"]], on=\"lambda\", how=\"inner\")\n",
    "    .sort_values(\"lambda\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "cross_layer_df[\"aet_echo_slope_norm\"] = minmax_norm(cross_layer_df[\"echo_slope\"])\n",
    "cross_layer_df[\"iwlt_entropy_density_norm\"] = minmax_norm(cross_layer_df[\"entropy_density\"])\n",
    "cross_layer_df[\"rlt_expansion_ratio_norm\"] = minmax_norm(cross_layer_df[\"expansion_ratio\"])\n",
    "\n",
    "fig_cross_layer = make_multiline_figure(\n",
    "    cross_layer_df,\n",
    "    \"lambda\",\n",
    "    [\n",
    "        {\"y_col\": \"aet_echo_slope_norm\", \"name\": \"AET echo slope\", \"color\": \"#1f77b4\"},\n",
    "        {\"y_col\": \"iwlt_entropy_density_norm\", \"name\": \"IWLT entropy density\", \"color\": \"#d95f02\"},\n",
    "        {\"y_col\": \"rlt_expansion_ratio_norm\", \"name\": \"RLT expansion ratio\", \"color\": \"#1b9e77\"},\n",
    "    ],\n",
    "    \"Cross-Layer Normalized Structural Measures vs Lambda\",\n",
    "    \"normalized value\",\n",
    ")\n",
    "cross_layer_png = save_png(fig_cross_layer, \"fig_cross_layer_summary_vs_lambda.png\")\n",
    "display_saved_png(cross_layer_png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export"
   },
   "outputs": [],
   "source": [
    "pngs = sorted(path.name for path in OUTPUT_DIR.glob(\"*.png\"))\n",
    "print(\"Saved PNGs:\")\n",
    "for name in pngs:\n",
    "    print(\" -\", name)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "dsfb_add_sweep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "dsfb_add_notebook_version": "2026-03-01-10"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
